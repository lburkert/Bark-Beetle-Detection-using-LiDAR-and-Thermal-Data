{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pre processing and Tree Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitebox import WhiteboxTools\n",
    "import laspy\n",
    "import pdal\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import rasterio\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# set root directory\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "# Falls dein preprocessing-Ordner im Projekt liegt:\n",
    "WORK_DIR = BASE_DIR / \"preprocessing\"\n",
    "\n",
    "# Whitebox initialisieren\n",
    "wbt = WhiteboxTools()\n",
    "wbt.set_working_dir(str(WORK_DIR))\n",
    "\n",
    "print(\"Working directory:\", wbt.work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Ground classification with Cloth Simulation Filter (CSF) [Zhang et al., 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define folders ---\n",
    "INPUT_FILE = WORK_DIR / \"Wenns_Data\" / \"PC\" / \"Wenns_aoi.las\"\n",
    "OUTPUT_DIR = WORK_DIR / \"output_lidar\"\n",
    "\n",
    "# --- Output ---\n",
    "ALL_FILE = OUTPUT_DIR / \"las_ground_nonground.las\"\n",
    "GROUND_FILE = OUTPUT_DIR / \"ground_csf.las\"\n",
    "NONGROUND_FILE = OUTPUT_DIR / \"nonground_csf.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize json pipeline\n",
    "json_pipeline = {\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "            \"type\": \"readers.las\",\n",
    "            \"filename\": str(INPUT_FILE)\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"type\": \"filters.assign\",\n",
    "            \"value\": [\n",
    "            \"ReturnNumber = 1 WHERE ReturnNumber < 1\",\n",
    "            \"NumberOfReturns = 1 WHERE NumberOfReturns < 1\"\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"type\": \"filters.outlier\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.csf\",\n",
    "            \"resolution\": 0.2,\n",
    "        },\n",
    "        # Export all\n",
    "        {\n",
    "            \"type\": \"writers.las\",\n",
    "            \"filename\": str(ALL_FILE),\n",
    "        },\n",
    "\n",
    "        # Ground export\n",
    "        {\n",
    "            \"type\": \"writers.las\",\n",
    "            \"filename\": str(GROUND_FILE),\n",
    "            \"where\": \"Classification == 2\"\n",
    "        },\n",
    "\n",
    "        # Non-ground export\n",
    "        {\n",
    "            \"type\": \"writers.las\",\n",
    "            \"filename\": str(NONGROUND_FILE),\n",
    "            \"where\": \"Classification != 2\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "json_pipeline = json.dumps(json_pipeline)\n",
    "\n",
    "pipeline = pdal.Pipeline(json_pipeline)\n",
    "count = pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Create DTM, DSM and CHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_ground_nonground = laspy.read(\"preprocessing/output_lidar/las_ground_nonground.las\")\n",
    "\n",
    "xmin, xmax = np.min(las_ground_nonground.x), np.max(las_ground_nonground.x)\n",
    "ymin, ymax = np.min(las_ground_nonground.y), np.max(las_ground_nonground.y)\n",
    "\n",
    "print(xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Check for different classifications so they can be excluded in the next step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(las_ground_nonground.classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Create DEM (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_TIF = WORK_DIR / \"output_rast\"\n",
    "\n",
    "INPUT_LAS = OUTPUT_DIR / \"las_ground_nonground.las\"\n",
    "DEM_FILE = OUTPUT_TIF / \"raw_dem.tif\"\n",
    "DSM_FILE = OUTPUT_TIF / \"raw_dsm.tif\"\n",
    "CHM_FILE = OUTPUT_TIF / \"raw_chm.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interpolating DEM...\")\n",
    "wbt.lidar_idw_interpolation(\n",
    "i=str(INPUT_LAS),\n",
    "output=str(DEM_FILE),\n",
    "parameter=\"elevation\",\n",
    "returns=\"all\",\n",
    "resolution=0.2,\n",
    "weight=1.0,\n",
    "radius=2.5,\n",
    "exclude_cls='0,1,7'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Create DSM (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interpolating DSM...\")\n",
    "wbt.lidar_idw_interpolation(\n",
    "i=str(INPUT_LAS),\n",
    "output=str(DSM_FILE),\n",
    "parameter=\"elevation\",\n",
    "returns=\"first\",\n",
    "resolution=0.2,\n",
    "weight=1.0,\n",
    "radius=2.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Create CHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating CHM...\")\n",
    "wbt.subtract(\n",
    "    input1=str(DSM_FILE),\n",
    "    input2=str(DEM_FILE),\n",
    "    output=str(CHM_FILE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Define CRS for DTM,DSM and CHM and smooth with gaussina filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter \n",
    "\n",
    "with rasterio.open(str(DEM_FILE), \"r+\") as dataset:\n",
    "    dataset.crs = \"EPSG:32632\"\n",
    "    print(dataset.crs)\n",
    "\n",
    "with rasterio.open(str(DSM_FILE), \"r+\") as dataset:\n",
    "    dataset.crs = \"EPSG:32632\"\n",
    "    print(dataset.crs)\n",
    "    \n",
    "\n",
    "with rasterio.open(str(CHM_FILE), \"r+\") as dataset:\n",
    "    dataset.crs = \"EPSG:32632\"\n",
    "    print(dataset.crs)\n",
    "\n",
    "    chm = dataset.read(1, masked=True).astype(\"float32\")\n",
    "    profile = dataset.profile\n",
    "\n",
    "    chm_filled = chm.filled(0)\n",
    "    chm_smoothed = median_filter(chm_filled, size=5)\n",
    "\n",
    "    # mask no-data\n",
    "    chm_smoothed[chm.mask] = dataset.nodata\n",
    "\n",
    "    profile.update(dtype=chm_smoothed.dtype)\n",
    "\n",
    "    with rasterio.open(\"chm_filtered.tif\", \"w\", **profile) as dst:\n",
    "        dst.write(chm_smoothed, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Normalize Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LAS = OUTPUT_DIR / \"nonground_csf.las\"\n",
    "NORM_LAS = OUTPUT_DIR / \"normalized_pc.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.normalize_lidar(\n",
    "    i=str(INPUT_LAS),\n",
    "    output=str(NORM_LAS),\n",
    "    dtm=str(DEM_FILE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_normalized = laspy.read(str(NORM_LAS))\n",
    "np.min(las_normalized.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Individual Tree Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt.individual_tree_detection(\n",
    "    i=str(NORM_LAS), \n",
    "    output=\"treetops.shp\", \n",
    "    min_search_radius=1.0, \n",
    "    min_height=5.0, \n",
    "    max_search_radius=\"4\", \n",
    "    max_height=\"40\", \n",
    "    only_use_veg=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Before continuing run treeiso.py in command line on non ground pointcloud to segment individual trees!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LAS = OUTPUT_DIR / \"nonground_csf_treeiso.laz\"\n",
    "las_trees = laspy.read(str(INPUT_LAS))\n",
    "\n",
    "print(las_trees.header.vlrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Pycrown updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Create circular neighbourhood offsets\n",
    "# --------------------------------------------------\n",
    "@njit\n",
    "def create_circular_offsets(radius):\n",
    "    offsets = []\n",
    "    r2 = radius * radius\n",
    "    for dy in range(-radius, radius + 1):\n",
    "        for dx in range(-radius, radius + 1):\n",
    "            if dx * dx + dy * dy <= r2:\n",
    "                offsets.append((dy, dx))\n",
    "    return offsets\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Modern Dalponte CIRC\n",
    "# --------------------------------------------------\n",
    "@njit\n",
    "def crown_dalponte_circ(\n",
    "    chm,\n",
    "    tree_coords,     # shape (2, N) -> [x_coords, y_coords]\n",
    "    th_seed=0.45,\n",
    "    th_crown=0.55,\n",
    "    th_tree=2.0,\n",
    "    max_crown=10\n",
    "):\n",
    "    nrows, ncols = chm.shape\n",
    "    ntrees = tree_coords.shape[1]\n",
    "\n",
    "    crowns = np.zeros((nrows, ncols), dtype=np.int32)\n",
    "\n",
    "    # Track crown stats\n",
    "    npixel = np.ones(ntrees)\n",
    "    sum_height = np.zeros(ntrees)\n",
    "\n",
    "    offsets = create_circular_offsets(max_crown)\n",
    "\n",
    "    # Initialize seeds\n",
    "    for i in range(ntrees):\n",
    "        x = tree_coords[0, i]\n",
    "        y = tree_coords[1, i]\n",
    "        crowns[y, x] = i + 1\n",
    "        sum_height[i] = chm[y, x]\n",
    "\n",
    "    growing = True\n",
    "\n",
    "    while growing:\n",
    "        growing = False\n",
    "\n",
    "        for tidx in range(ntrees):\n",
    "\n",
    "            seed_x = tree_coords[0, tidx]\n",
    "            seed_y = tree_coords[1, tidx]\n",
    "            seed_h = chm[seed_y, seed_x]\n",
    "            mean_h = sum_height[tidx] / npixel[tidx]\n",
    "\n",
    "            for dy, dx in offsets:\n",
    "\n",
    "                ny = seed_y + dy\n",
    "                nx = seed_x + dx\n",
    "\n",
    "                # Bounds check\n",
    "                if ny < 1 or ny >= nrows - 1:\n",
    "                    continue\n",
    "                if nx < 1 or nx >= ncols - 1:\n",
    "                    continue\n",
    "\n",
    "                if crowns[ny, nx] != 0:\n",
    "                    continue\n",
    "\n",
    "                nb_h = chm[ny, nx]\n",
    "\n",
    "                # Dalponte growing criteria\n",
    "                if (\n",
    "                    nb_h > th_tree and\n",
    "                    nb_h > seed_h * th_seed and\n",
    "                    nb_h > mean_h * th_crown and\n",
    "                    nb_h <= seed_h * 1.05 and\n",
    "                    abs(seed_x - nx) <= max_crown and\n",
    "                    abs(seed_y - ny) <= max_crown\n",
    "                ):\n",
    "\n",
    "                    # 4-connectivity check\n",
    "                    if (\n",
    "                        crowns[ny - 1, nx] == tidx + 1 or\n",
    "                        crowns[ny + 1, nx] == tidx + 1 or\n",
    "                        crowns[ny, nx - 1] == tidx + 1 or\n",
    "                        crowns[ny, nx + 1] == tidx + 1\n",
    "                    ):\n",
    "                        crowns[ny, nx] = tidx + 1\n",
    "                        sum_height[tidx] += nb_h\n",
    "                        npixel[tidx] += 1\n",
    "                        growing = True\n",
    "\n",
    "    return crowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree crowns Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "import fiona\n",
    "\n",
    "def export_crowns_polygons(crowns, transform, epsg, out_file):\n",
    "    \"\"\"\n",
    "    Convert crowns raster to polygons and save as Shapefile\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        'geometry': 'Polygon',\n",
    "        'properties': {'DN': 'int'}\n",
    "    }\n",
    "\n",
    "    with fiona.open(out_file, 'w', driver='ESRI Shapefile',\n",
    "                    crs=f\"EPSG:{epsg}\", schema=schema) as shp:\n",
    "        for geom, value in shapes(crowns.astype(np.int32), mask=crowns>0,\n",
    "                                  transform=transform):\n",
    "            shp.write({\n",
    "                'geometry': mapping(shape(geom)),\n",
    "                'properties': {'DN': int(value)}\n",
    "            })\n",
    "    print(f\"Crowns shapefile exported: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Use circular dalponte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import treetops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Tree tops Shapefile\n",
    "tree_shp = \"tree_tops.shp\"\n",
    "trees_gdf = gpd.read_file(tree_shp)\n",
    "\n",
    "# Transform auf Raster-Index (row, col)\n",
    "tree_coords = []\n",
    "for x, y in zip(trees_gdf.geometry.x, trees_gdf.geometry.y):\n",
    "    col, row = ~transform * (x, y)  # inverse transform\n",
    "    col = int(round(col))\n",
    "    row = int(round(row))\n",
    "    # check bounds\n",
    "    if 0 <= row < nrows and 0 <= col < ncols:\n",
    "        tree_coords.append((col, row))\n",
    "\n",
    "# numpy array wie von pycrown erwartet\n",
    "tree_coords = np.array(tree_coords).T.astype(np.int32)  # shape (2, ntrees)\n",
    "print(\"Number of tree tops:\", tree_coords.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import CHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# CHM Pfad\n",
    "chm_path = \"chm.tif\"\n",
    "\n",
    "with rasterio.open(chm_path) as src:\n",
    "    chm = src.read(1)  # Single Band CHM\n",
    "    chm = chm.astype(np.float32)  # sicherstellen float32\n",
    "    transform = src.transform\n",
    "    epsg = src.crs.to_epsg()\n",
    "    nrows, ncols = chm.shape\n",
    "\n",
    "print(\"CHM shape:\", chm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Execute dalponte crown delineation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowns = crown_dalponte_circ(\n",
    "    chm_array,\n",
    "    tree_coords,\n",
    "    th_seed=0.7,\n",
    "    th_crown=0.55,\n",
    "    th_tree=15,\n",
    "    max_crown=10\n",
    ")\n",
    "\n",
    "export_crowns_polygons(crowns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TreeSegmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
